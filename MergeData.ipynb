{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af3dbd6",
   "metadata": {},
   "source": [
    "Gộp dữ liệu     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Cài đặt các thư viện\n",
    "!pip install roboflow pyyaml tqdm ultralytics --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698dd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import os\n",
    "\n",
    "# Sử dụng API key trực tiếp (chỉ dùng cho testing)\n",
    "rf = Roboflow(api_key=\"YOUT-KEY-ON-ROBOFLOW\")\n",
    "workspace = rf.workspace(\"objdetecpen\")\n",
    "\n",
    "# Tải datasets\n",
    "project_a = workspace.project(\"all-objects-1-z1qkf\")\n",
    "dataset_a = project_a.version(1).download(\"yolov8\")\n",
    "\n",
    "project_b = workspace.project(\"pen-x2n7a-x0key\")\n",
    "dataset_b = project_b.version(1).download(\"yolov8\")\n",
    "\n",
    "print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Dataset paths trên Kaggle\n",
    "dataset_a = \"/kaggle/working/All-objects-1-1\"\n",
    "dataset_b = \"/kaggle/working/pen-1\" \n",
    "merged = \"/kaggle/working/merged_with_eraser\"\n",
    "\n",
    "# Tạo thư mục\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    os.makedirs(os.path.join(merged, split, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(merged, split, \"labels\"), exist_ok=True)\n",
    "\n",
    "def copy_and_remap(src, dst, mapping):\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        img_dir = os.path.join(src, split, \"images\")\n",
    "        lbl_dir = os.path.join(src, split, \"labels\")\n",
    "        if not os.path.exists(img_dir): continue\n",
    "\n",
    "        # Copy ảnh\n",
    "        for file in os.listdir(img_dir):\n",
    "            shutil.copy(os.path.join(img_dir, file), os.path.join(dst, split, \"images\", file))\n",
    "\n",
    "        # Remap nhãn\n",
    "        for file in os.listdir(lbl_dir):\n",
    "            lbl_src = os.path.join(lbl_dir, file)\n",
    "            lbl_dst = os.path.join(dst, split, \"labels\", file)\n",
    "            \n",
    "            new_lines = []\n",
    "            with open(lbl_src, \"r\") as f:\n",
    "                for line in f:\n",
    "                    cls, *coords = line.strip().split()\n",
    "                    if int(cls) in mapping:\n",
    "                        new_lines.append(f\"{mapping[int(cls)]} {' '.join(coords)}\")\n",
    "            \n",
    "            if new_lines:\n",
    "                with open(lbl_dst, \"w\") as f:\n",
    "                    f.write(\"\\n\".join(new_lines))\n",
    "\n",
    "# Merge datasets\n",
    "copy_and_remap(dataset_a, merged, {0:0, 1:1, 2:2})  # Dataset A\n",
    "copy_and_remap(dataset_b, merged, {0:1})             # Dataset B\n",
    "\n",
    "# Tạo file data.yaml\n",
    "with open(os.path.join(merged, \"data.yaml\"), \"w\") as f:\n",
    "    f.write(f\"\"\"path: {merged}\n",
    "train: train/images\n",
    "val: valid/images\n",
    "test: test/images\n",
    "\n",
    "names:\n",
    "  0: eraser\n",
    "  1: pen\n",
    "  2: pencil\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ Dataset merged tại:\", merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    imgs = glob.glob(f\"{merged}/{split}/images/*.jpg\")\n",
    "    lbls = glob.glob(f\"{merged}/{split}/labels/*.txt\")\n",
    "    print(f\"{split}: {len(imgs)} images, {len(lbls)} labels\")\n",
    "\n",
    "# Đếm instance từng class\n",
    "counts = {\"eraser\": 0, \"pen\": 0, \"pencil\": 0}\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    for lbl_file in glob.glob(f\"{merged}/{split}/labels/*.txt\"):\n",
    "        with open(lbl_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                cls = int(line.split()[0])\n",
    "                if cls == 0:\n",
    "                    counts[\"eraser\"] += 1\n",
    "                elif cls == 1:\n",
    "                    counts[\"pen\"] += 1\n",
    "                elif cls == 2:\n",
    "                    counts[\"pencil\"] += 1\n",
    "\n",
    "print(\"\\nSố lượng instance sau merge:\")\n",
    "print(counts)\n",
    "\n",
    "#train: 3211 images, 3209 labels\n",
    "#valid: 689 images, 689 labels\n",
    "#test: 334 images, 334 labels\n",
    "\n",
    "#Số lượng instance sau merge:\n",
    "#{'eraser': 916, 'pen': 2972, 'pencil': 2800}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
